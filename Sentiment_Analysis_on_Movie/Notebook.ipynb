{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Sentiment Analysis on Movie.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8kfG4wMh4tdEZyCgjm7CI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JawDri/Kaggle-Competitions/blob/master/Sentiment_Analysis_on_Movie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbeFmp4kFksV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz2sPv4uHatU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from bs4 import BeautifulSoup\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqAuPGkqHvcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import random\n",
        "import tensorflow\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Dense,Dropout,Embedding,LSTM,Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4AbXLjdNsvu",
        "colab_type": "text"
      },
      "source": [
        "Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEFTZCm4KkGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train= pd.read_csv(\"../content/train.tsv.zip\", sep=\"\\t\")\n",
        "test = pd.read_csv(\"../content/test.tsv.zip\", sep=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK_5hwAsNLzP",
        "colab_type": "code",
        "outputId": "51e6843a-2260-4232-905c-55852c9b05c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfuWI99qN4U1",
        "colab_type": "code",
        "outputId": "c3cc5094-8233-41c1-dbf5-38032bb4b505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156060, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwpYy2qDNOxh",
        "colab_type": "code",
        "outputId": "89d84fdf-474c-4ce3-d2b3-5fb26c2ded1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>156061</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156062</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>156063</td>\n",
              "      <td>8545</td>\n",
              "      <td>An</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>156064</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine effort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>156065</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  SentenceId                                             Phrase\n",
              "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
              "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
              "2    156063        8545                                                 An\n",
              "3    156064        8545  intermittently pleasing but mostly routine effort\n",
              "4    156065        8545         intermittently pleasing but mostly routine"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo-q6fATN6TM",
        "colab_type": "code",
        "outputId": "57fe4a8b-82d6-4265-8533-e49a3933ea8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(66292, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om3VBaeBO0gc",
        "colab_type": "text"
      },
      "source": [
        "Clean, Tokenize and Lemmatize\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdLnsgGYPP0q",
        "colab_type": "text"
      },
      "source": [
        "1.     remove html content\n",
        "2.     remove non-alphabetic characters\n",
        "3.     tokenize the sentences\n",
        "4.     lemmatize each word to its lemma\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MupmaKaNOTXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TQDM is a progress bar library with good support for nested loops and Jupyter/IPython notebooks (--tqdm == تقدم--)\n",
        "from tqdm import tqdm\n",
        "def clean_sentences(df):\n",
        "    reviews = []\n",
        "\n",
        "    for sent in tqdm(df['Phrase']):\n",
        "        \n",
        "        #remove html content\n",
        "        review_text = BeautifulSoup(sent).get_text()\n",
        "        \n",
        "        #remove non-alphabetic characters\n",
        "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
        "    \n",
        "        #tokenize the sentences\n",
        "        words = word_tokenize(review_text.lower())\n",
        "    \n",
        "        #lemmatize each word to its lemma\n",
        "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
        "    \n",
        "        reviews.append(lemma_words)\n",
        "\n",
        "    return(reviews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgPJB1vzVZ5w",
        "colab_type": "code",
        "outputId": "bbbad48f-42a8-40c2-bb99-a776326cdb73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "#cleaned reviews for both train and test set retrieved\n",
        "train_sentences = clean_sentences(train)\n",
        "test_sentences = clean_sentences(test)\n",
        "print(len(train_sentences))\n",
        "print(len(test_sentences))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 156060/156060 [01:17<00:00, 2004.61it/s]\n",
            "100%|██████████| 66292/66292 [00:31<00:00, 2076.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "156060\n",
            "66292\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ76Nv0JZYwT",
        "colab_type": "text"
      },
      "source": [
        "Collect the dependent values and convert to one-hot encoded output using to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BELzAPtHXfeG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target=train.Sentiment.values\n",
        "y_target=to_categorical(target)\n",
        "num_classes=y_target.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6aJTCpsaTiT",
        "colab_type": "text"
      },
      "source": [
        "Split train/validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wulqp5GkYLEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_val,y_train,y_val=train_test_split(train_sentences,y_target,test_size=0.2,stratify=y_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbxhW5oFsprJ",
        "colab_type": "text"
      },
      "source": [
        "Number of unique words and max length of a review available in the list of cleaned reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUpVVFYPaxmc",
        "colab_type": "code",
        "outputId": "a786ff78-8657-4b82-8efa-a9b12f82d801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "unique_words = set()\n",
        "len_max = 0\n",
        "\n",
        "for sent in tqdm(X_train):\n",
        "    \n",
        "    unique_words.update(sent)\n",
        "    \n",
        "    if(len_max<len(sent)):\n",
        "        len_max = len(sent)\n",
        "        \n",
        "#length of the list of unique_words gives the no of unique words\n",
        "print('\\n',len(list(unique_words)))\n",
        "print(len_max)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 124848/124848 [00:00<00:00, 555361.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 13739\n",
            "48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoCXKKwot7ku",
        "colab_type": "text"
      },
      "source": [
        "Tokenizer/ convert to sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7CSenIYtS0Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92dbdde8-aab0-4214-cd1f-b5ae3327966a"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
        "tokenizer.fit_on_texts(list(X_train))\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "X_test = tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "#padding /LSTM networks needs all inputs to be same length.\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=len_max)\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=len_max)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=len_max)\n",
        "\n",
        "print(X_train.shape,X_val.shape,X_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(124848, 48) (31212, 48) (66292, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VffQaNicv5kS",
        "colab_type": "text"
      },
      "source": [
        "CallBack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhfoHvN0vnsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stopping = EarlyStopping(min_delta = 0.001, mode = 'auto', monitor='val_acc', patience = 1)\n",
        "callback = [early_stopping]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0xjQ-3wxtcO",
        "colab_type": "text"
      },
      "source": [
        "Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHeb6zq1v7xC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "bc3e3077-b3b5-4e8d-b229-f54e83871f57"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(list(unique_words)),300,input_length=len_max))\n",
        "model.add(LSTM(128,dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\n",
        "model.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.005),metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 48, 300)           4121700   \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               (None, 48, 128)           219648    \n",
            "_________________________________________________________________\n",
            "lstm_19 (LSTM)               (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 100)               6500      \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 4,397,761\n",
            "Trainable params: 4,397,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAUu_pLLQW2j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "c478978b-5420-4d42-8544-7b521aca29cf"
      },
      "source": [
        "history=model.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=6, batch_size=256, verbose=1, callbacks=callback)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "488/488 [==============================] - ETA: 0s - loss: 0.9808 - accuracy: 0.6034WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "488/488 [==============================] - 276s 566ms/step - loss: 0.9808 - accuracy: 0.6034 - val_loss: 0.8418 - val_accuracy: 0.6519\n",
            "Epoch 2/6\n",
            "488/488 [==============================] - ETA: 0s - loss: 0.7913 - accuracy: 0.6754WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "488/488 [==============================] - 274s 562ms/step - loss: 0.7913 - accuracy: 0.6754 - val_loss: 0.8137 - val_accuracy: 0.6689\n",
            "Epoch 3/6\n",
            "488/488 [==============================] - ETA: 0s - loss: 0.7206 - accuracy: 0.7001WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "488/488 [==============================] - 274s 561ms/step - loss: 0.7206 - accuracy: 0.7001 - val_loss: 0.8063 - val_accuracy: 0.6721\n",
            "Epoch 4/6\n",
            "488/488 [==============================] - ETA: 0s - loss: 0.6782 - accuracy: 0.7148WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "488/488 [==============================] - 276s 565ms/step - loss: 0.6782 - accuracy: 0.7148 - val_loss: 0.8224 - val_accuracy: 0.6731\n",
            "Epoch 5/6\n",
            "488/488 [==============================] - ETA: 0s - loss: 0.6480 - accuracy: 0.7267WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "488/488 [==============================] - 274s 562ms/step - loss: 0.6480 - accuracy: 0.7267 - val_loss: 0.8514 - val_accuracy: 0.6703\n",
            "Epoch 6/6\n",
            "488/488 [==============================] - ETA: 0s - loss: 0.6304 - accuracy: 0.7318WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "488/488 [==============================] - 275s 563ms/step - loss: 0.6304 - accuracy: 0.7318 - val_loss: 0.8931 - val_accuracy: 0.6637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZQteOJDCMIj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "f636c051-88d1-4f97-dad4-cb346a4ecb6d"
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(list(unique_words)), 100, input_length=len_max))\n",
        "model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(num_classes/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 48, 100)           1373900   \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 48, 300)           301200    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 48, 300)           0         \n",
            "_________________________________________________________________\n",
            "lstm_21 (LSTM)               (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 2)                 202       \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 5)                 15        \n",
            "=================================================================\n",
            "Total params: 1,835,717\n",
            "Trainable params: 1,835,717\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S0rguOr2tDK",
        "colab_type": "text"
      },
      "source": [
        "Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWOPfd4b2pBo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "34640b4e-a99e-4bb0-9408-d4927b5af1c3"
      },
      "source": [
        "history=model.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=6, batch_size=100, verbose=1, callbacks=callback)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "1248/1249 [============================>.] - ETA: 0s - loss: 1.1691 - accuracy: 0.5174WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1249/1249 [==============================] - 82s 66ms/step - loss: 1.1692 - accuracy: 0.5174 - val_loss: 1.0893 - val_accuracy: 0.5601\n",
            "Epoch 2/6\n",
            "1249/1249 [==============================] - ETA: 0s - loss: 0.9978 - accuracy: 0.6178WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1249/1249 [==============================] - 81s 65ms/step - loss: 0.9978 - accuracy: 0.6178 - val_loss: 0.9360 - val_accuracy: 0.6362\n",
            "Epoch 3/6\n",
            "1249/1249 [==============================] - ETA: 0s - loss: 0.8249 - accuracy: 0.6825WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1249/1249 [==============================] - 81s 65ms/step - loss: 0.8249 - accuracy: 0.6825 - val_loss: 0.8602 - val_accuracy: 0.6586\n",
            "Epoch 4/6\n",
            "1249/1249 [==============================] - ETA: 0s - loss: 0.7487 - accuracy: 0.7077WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1249/1249 [==============================] - 82s 66ms/step - loss: 0.7487 - accuracy: 0.7077 - val_loss: 0.8457 - val_accuracy: 0.6636\n",
            "Epoch 5/6\n",
            "1249/1249 [==============================] - ETA: 0s - loss: 0.7037 - accuracy: 0.7231WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1249/1249 [==============================] - 83s 66ms/step - loss: 0.7037 - accuracy: 0.7231 - val_loss: 0.8368 - val_accuracy: 0.6654\n",
            "Epoch 6/6\n",
            "1249/1249 [==============================] - ETA: 0s - loss: 0.6697 - accuracy: 0.7346WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1249/1249 [==============================] - 82s 65ms/step - loss: 0.6697 - accuracy: 0.7346 - val_loss: 0.8440 - val_accuracy: 0.6648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDNvbv7G5OBI",
        "colab_type": "text"
      },
      "source": [
        "Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJoOacE15M5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make the predictions with trained model and submit the predictions.\n",
        "y_pred=model.predict_classes(X_test)\n",
        "\n",
        "sub_file = pd.read_csv('../content/sampleSubmission.csv',sep=',')\n",
        "sub_file.Sentiment=y_pred\n",
        "sub_file.to_csv('Submission.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
